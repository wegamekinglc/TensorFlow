{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "test_images = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "train_images = train_images / 255.\n",
    "test_images = test_images / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation=keras.activations.relu, input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation=keras.activations.relu))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation=keras.activations.relu))\n",
    "model.add(keras.layers.Dense(10, activation=keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 4ms/step - loss: 0.6198 - accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3077 - accuracy: 0.8870\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2493 - accuracy: 0.9075\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2158 - accuracy: 0.9194\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1866 - accuracy: 0.9305\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1630 - accuracy: 0.9392\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1447 - accuracy: 0.9450\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1258 - accuracy: 0.9499\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1122 - accuracy: 0.9580\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0961 - accuracy: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24d15dc9dc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.9098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30466291308403015, 0.9097999930381775]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = activation_model.predict(test_images[0].reshape((1, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24d49f47d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[1][0, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 26, 26, 64) dtype=float32 (created by layer 'conv2d')>,\n",
       " <KerasTensor: shape=(None, 13, 13, 64) dtype=float32 (created by layer 'max_pooling2d')>,\n",
       " <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'conv2d_1')>,\n",
       " <KerasTensor: shape=(None, 5, 5, 64) dtype=float32 (created by layer 'max_pooling2d_1')>,\n",
       " <KerasTensor: shape=(None, 1600) dtype=float32 (created by layer 'flatten')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'dense')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_1')>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array([\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser', 'Trouser', 'Shirt', 'Trouser',\n",
       "       'Coat', 'Shirt', 'Sandal', 'Sneaker'], dtype='<U11')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[np.argmax(model.predict(test_images[0:10]), -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
